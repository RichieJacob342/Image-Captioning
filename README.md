# Image-Captioning

The model is based on cnn-lstm neural networks which automatically detects the objects in the images and generates description for the images.

The model can perform 2 operations.
The VGG16 Model is to detect objects in the image using Convolutional Neural Networks and the other is to caption the images using RNN based LSTM (Long Short Term Memory).

Detailed explanation is given through the Report.pdf uploaded.

Training of the model is done through google colab.
Front-end Software: Django,HTML, CSS, Web browser.
Back-end Software: Sklearn,pandas and various other requirements that have been solved by using Google colab.

Working of this project:
django\ImageCaption\home
In the above path copy the model_18.h5 file.
The model_18.h5 will be provided when u train the program in colab.
Then in terminal or cmd run the program as python manage.py runserver
and before this install all the library

